{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasonadu/gpt_in_practice/blob/main/3.%20%E5%88%9D%E8%AF%86LangChain%EF%BD%9C%E4%BD%A0%E7%9A%84%E7%91%9E%E5%A3%AB%E5%86%9B%E5%88%80%20-%20Qwen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de6a55d2",
      "metadata": {
        "id": "de6a55d2"
      },
      "source": [
        "# 回顾"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6a4415ee",
      "metadata": {
        "id": "6a4415ee"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=userdata.get('DASHSCOPE_API_KEY'),\n",
        "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
        ")\n",
        "\n",
        "def analyze_user_review(text):\n",
        "    messages = []\n",
        "    messages.append( {\"role\": \"system\",\n",
        "              \"content\": \"\"\"\n",
        "              You are an assistant.\n",
        "              Please, analyze the user reviews according to the following instruction:\n",
        "              If the review is postive, you should output 'Y', otherwise output 'N'\n",
        "              \"\"\"})\n",
        "    messages.append( {\"role\": \"user\", \"content\": text})\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"qwen-plus\",\n",
        "        messages=messages\n",
        "    )\n",
        "    return response.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "56058099",
      "metadata": {
        "id": "56058099",
        "outputId": "8f1062c0-a5b2-4b0a-9878-86eeedec4f9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Y'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "analyze_user_review(\"服务热情周到。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9a5473f9",
      "metadata": {
        "id": "9a5473f9",
        "outputId": "8afcf45e-0129-4657-e358-473c0b74ba66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'N'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "analyze_user_review(\"不理不睬。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "017882d2",
      "metadata": {
        "id": "017882d2",
        "outputId": "fbef56a1-f55b-4782-9938-9f09560dcab6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'N'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "analyze_user_review(\"用餐环境差，等待时间长。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7537df8a",
      "metadata": {
        "id": "7537df8a",
        "outputId": "cd55dcfc-ea62-4d08-ef32-c5b73f8f4c36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.72)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.10)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.42)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show langchain"
      ],
      "metadata": {
        "id": "PLySNKCG56ab",
        "outputId": "f7181487-b046-4271-8e5d-21a656923024",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "PLySNKCG56ab",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langchain\n",
            "Version: 0.3.27\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: langchain-core, langchain-text-splitters, langsmith, pydantic, PyYAML, requests, SQLAlchemy\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dashscope\n",
        "!pip install -qU langchain-community"
      ],
      "metadata": {
        "id": "v4u7guDM6Dq7",
        "outputId": "69d4da5e-b5ce-4d92-8681-1eddc3ba7baa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "v4u7guDM6Dq7",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dashscope\n",
            "  Downloading dashscope-1.24.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from dashscope) (3.12.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from dashscope) (2.32.3)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from dashscope) (1.8.0)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from dashscope) (43.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope) (1.20.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography->dashscope) (1.17.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->dashscope) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->dashscope) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->dashscope) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->dashscope) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp->dashscope) (4.14.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography->dashscope) (2.22)\n",
            "Downloading dashscope-1.24.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dashscope\n",
            "Successfully installed dashscope-1.24.1\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e1d51c9",
      "metadata": {
        "id": "8e1d51c9"
      },
      "source": [
        "# 提示词模版"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a9749461",
      "metadata": {
        "id": "a9749461",
        "outputId": "f079a855-06f0-4a24-aa9d-0b2a7151822f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Innovatech Solutions\n",
            "content='Innovatech Solutions' additional_kwargs={} response_metadata={'model_name': 'qwen-plus', 'finish_reason': 'stop', 'request_id': '7d8ec099-ba40-97ea-9f57-38c0928ce594', 'token_usage': {'input_tokens': 32, 'output_tokens': 5, 'total_tokens': 37, 'prompt_tokens_details': {'cached_tokens': 0}}} id='run--1833f2db-47b7-415c-b2fa-9aa8a9706f44-0'\n"
          ]
        }
      ],
      "source": [
        "# https://python.langchain.com/docs/integrations/chat/tongyi/\n",
        "from langchain import PromptTemplate, OpenAI, LLMChain\n",
        "from langchain_community.chat_models.tongyi import ChatTongyi\n",
        "\n",
        "# prompt_template = \"What is a good name for a company that makes {product}? And only return the best one.\"\n",
        "prompt_template_str = \"What is a good name for a company that makes {{product}}? And only return the best one.\"\n",
        "prompt_template = PromptTemplate.from_template(prompt_template_str)\n",
        "\n",
        "llm = ChatTongyi(model_name=\"qwen-plus\", temperature=0, max_tokens=200,\n",
        "                 dashscope_api_key=userdata.get('DASHSCOPE_API_KEY')) # dashscope_api_key is required\n",
        "\n",
        "'''\n",
        "LangChainDeprecationWarning:\n",
        "The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
        "The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
        "'''\n",
        "# llm_chain = LLMChain(\n",
        "#     llm=llm,\n",
        "#     prompt=PromptTemplate.from_template(prompt_template)\n",
        "# )\n",
        "# llm_chain.run(\"colorful socks\")\n",
        "\n",
        "# 使用新的方式构建Runnable序列\n",
        "llm_chain = prompt_template | llm\n",
        "\n",
        "# 使用.invoke()方法运行链\n",
        "response = llm_chain.invoke({\"input\": \"colorful socks\"})\n",
        "print(response.content)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3e5f2fbf",
      "metadata": {
        "id": "3e5f2fbf",
        "outputId": "1debd975-42b2-4a42-9441-9988fdfa7fa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1953156135.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  llm_chain = LLMChain(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': 'InnovateCraft'}, {'text': 'Innovexa'}, {'text': 'InnovateCraft'}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "llm_chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=prompt_template\n",
        ")\n",
        "\n",
        "products = [{\"product\":\"'cloudnative devops platform'\"},\n",
        "            {\"product\":\"'Noise cancellation headphone'\"},\n",
        "            {\"product\":\"colorful socks\"}]\n",
        "llm_chain.apply(products)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9edff0fc",
      "metadata": {
        "id": "9edff0fc"
      },
      "source": [
        "# API调用链\n",
        "## HTTP request chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7125db24",
      "metadata": {
        "id": "7125db24"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate, OpenAI, LLMChain\n",
        "from langchain.chains import LLMRequestsChain\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "# from langchain.chat_models import ChatOpenAI #直接访问OpenAI的GPT服务\n",
        "\n",
        "#llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0) #直接访问OpenAI的GPT服务\n",
        "llm = AzureChatOpenAI(deployment_name = deployment, model_name=model, temperature=0, max_tokens=200) #通过Azure的OpenAI服务\n",
        "\n",
        "def query_baidu(question):\n",
        "      template = \"\"\"Between >>> and <<< are the raw search result text from web.\n",
        "      Extract the answer to the question '{query}' or say \"not found\" if the information is not contained.\n",
        "      Use the format\n",
        "      Extracted:<answer or \"not found\">\n",
        "      >>> {requests_result} <<<\n",
        "      Extracted:\"\"\"\n",
        "\n",
        "      PROMPT = PromptTemplate(\n",
        "          input_variables=[\"query\", \"requests_result\"],\n",
        "          template=template,\n",
        "      )\n",
        "\n",
        "      inputs = {\n",
        "          \"query\": question,\n",
        "          \"url\": \"http://www.baidu.com/s?wd=\" + question.replace(\" \", \"+\")\n",
        "      }\n",
        "      requests_chain = LLMRequestsChain(llm_chain = LLMChain(llm=llm, prompt=PROMPT), output_key=\"query_info\", verbose=True)\n",
        "      res = requests_chain.run(inputs)\n",
        "      return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39ac85a9",
      "metadata": {
        "id": "39ac85a9",
        "outputId": "9fa1e351-1ffe-47c2-ad2d-9e5b7c6fda5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMRequestsChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'23°晴东南风1级20~26°C'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_baidu(\"今天北京天气？\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ca99892",
      "metadata": {
        "id": "9ca99892"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.environ[\"SERPER_API_KEY\"] = \"\"\n",
        "# https://serper.dev\n",
        "from langchain.utilities import GoogleSerperAPIWrapper\n",
        "def query_web(question):\n",
        "    search = GoogleSerperAPIWrapper()\n",
        "    return search.run(question)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "681ec2dc",
      "metadata": {
        "id": "681ec2dc",
        "outputId": "ee1fadcf-cdc6-47c9-992e-bb126bd144d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'72°F'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_web(\"今天北京天气？\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36ed7650",
      "metadata": {
        "id": "36ed7650"
      },
      "source": [
        "# 调用链"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "073cc55c",
      "metadata": {
        "id": "073cc55c"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate, OpenAI, LLMChain\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.chains import SequentialChain\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "# from langchain.chat_models import ChatOpenAI #直接访问OpenAI的GPT服务\n",
        "\n",
        "#llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0) #直接访问OpenAI的GPT服务\n",
        "llm = AzureChatOpenAI(deployment_name = deployment, model_name=model, temperature=0, max_tokens=200)\n",
        "\n",
        "summarizing_prompt_template = \"\"\"\n",
        "Summarize the following content into a sentence less than 20 words:\n",
        "---\n",
        "{content}\n",
        "\n",
        "\"\"\"\n",
        "summarizing_chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=PromptTemplate.from_template(summarizing_prompt_template),\n",
        "    output_key = \"summary\"\n",
        ")\n",
        "\n",
        "translating_prompt_template = \"\"\"\n",
        "translate \"{summary}\" into Chinese:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "translating_chain = LLMChain(\n",
        "    llm = llm,\n",
        "    prompt=PromptTemplate.from_template(translating_prompt_template),\n",
        "    output_key = \"translated\"\n",
        ")\n",
        "\n",
        "overall_chain = SequentialChain(\n",
        "    chains=[summarizing_chain, translating_chain],\n",
        "    input_variables=[\"content\"],\n",
        "    output_variables=[ \"summary\",\"translated\"],\n",
        "    verbose=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "778d79d2",
      "metadata": {
        "id": "778d79d2",
        "outputId": "95201ce1-89df-4905-a6e7-1370ce627dca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "summary:LangChain is a framework for creating applications powered by language models, offering data-aware and agentic features, modular components, and pre-assembled chains for specific tasks.\n",
            "中文:\"LangChain是一个用于创建由语言模型驱动的应用程序的框架，提供数据感知和代理特性，模块化组件，以及针对特定任务的预组装链条。\"\n"
          ]
        }
      ],
      "source": [
        "res = overall_chain(\"\"\"\n",
        "LangChain is a framework for developing applications powered by language models. It enables applications that are:\n",
        "\n",
        "Data-aware: connect a language model to other sources of data\n",
        "Agentic: allow a language model to interact with its environment\n",
        "The main value props of LangChain are:\n",
        "\n",
        "Components: abstractions for working with language models, along with a collection of implementations for each abstraction. Components are modular and easy-to-use, whether you are using the rest of the LangChain framework or not\n",
        "Off-the-shelf chains: a structured assembly of components for accomplishing specific higher-level tasks\n",
        "Off-the-shelf chains make it easy to get started. For more complex applications and nuanced use-cases, components make it easy to customize existing chains or build new ones.\n",
        "\"\"\")\n",
        "\n",
        "print(\"summary:\"+res[\"summary\"])\n",
        "\n",
        "print(\"中文:\"+res[\"translated\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b00c5ce",
      "metadata": {
        "id": "1b00c5ce"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}